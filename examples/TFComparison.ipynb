{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python3.6Test",
      "language": "python",
      "name": "python3.6test"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "colab": {
      "name": "Comparison.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "surprised-apache"
      },
      "source": [
        "# Importing the libraries"
      ],
      "id": "surprised-apache"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "advanced-andrews"
      },
      "source": [
        "import time\n",
        "import xgboost\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from urllib.request import urlretrieve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "id": "advanced-andrews",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abandoned-detective"
      },
      "source": [
        "# Importing the dataset\n",
        "For this problem, I considered the CoverType dataset. It has seven classes and 581012 instances, and 54 features."
      ],
      "id": "abandoned-detective"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reported-worst"
      },
      "source": [
        "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz', header = None)\n",
        "data.head()\n",
        "\n",
        "\n",
        "featuer = []\n",
        "for i in range(len(data.columns)-1):\n",
        "  featuer.append(str(i))\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "# Replace the header with String value \n",
        "col_rename = {i:j for i,j in zip(df.columns, featuer)}\n",
        "df = df.rename(columns=col_rename, inplace=False)\n",
        "df.head()\n",
        "\n",
        "X = (df.iloc[:,:-1]).values\n",
        "y = (df.iloc[:, -1]).values\n",
        "\n",
        "for i in range(len(np.unique(y)-1)):\n",
        "    y[:][y[:] == i+1] = i\n",
        "\n",
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "dftrain, dfeval, y_train, y_eval = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=2)"
      ],
      "id": "reported-worst",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaXnQCMC4_XV"
      },
      "source": [
        "## Defining the TensorFlow BoostedTree\n"
      ],
      "id": "DaXnQCMC4_XV"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAyiwiJmn_HJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07d3f9b0-1749-4dd5-9ec1-7a8cb65a3bf6"
      },
      "source": [
        "NUM_EXAMPLES = len(y_train)\n",
        "\n",
        "\n",
        "def make_input_fn(X, y, n_epochs=None, shuffle=True):\n",
        "    def input_fn():\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))\n",
        "        if shuffle:\n",
        "            dataset = dataset.shuffle(NUM_EXAMPLES)\n",
        "\n",
        "        dataset = dataset.repeat(n_epochs)\n",
        "\n",
        "        dataset = dataset.batch(NUM_EXAMPLES)\n",
        "        return dataset\n",
        "    return input_fn\n",
        "\n",
        "\n",
        "# Training and evaluation input functions.\n",
        "train_input_fn = make_input_fn(dftrain, y_train)\n",
        "eval_input_fn = make_input_fn(dfeval, y_eval, shuffle=False, n_epochs=1)\n",
        "\n",
        "\n",
        "NUMERIC_COLUMNS = featuer\n",
        "\n",
        "\n",
        "feature_columns = []\n",
        "\n",
        "\n",
        "for feature_name in NUMERIC_COLUMNS:\n",
        "    feature_columns.append(tf.feature_column.numeric_column(feature_name,\n",
        "                                                            dtype=tf.float32))\n",
        "\n",
        "\n",
        "est = tf.estimator.BoostedTreesClassifier(feature_columns,\n",
        "                                          n_batches_per_layer=1,\n",
        "                                          n_classes=7,\n",
        "                                          n_trees=1,\n",
        "                                          max_depth=1)\n",
        "\n",
        "est.train(train_input_fn, max_steps=100)\n",
        "\n",
        "est.evaluate(eval_input_fn)"
      ],
      "id": "JAyiwiJmn_HJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp1rk6_i60\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp1rk6_i60', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "WARNING:tensorflow:Issue encountered when serializing resources.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'_Resource' object has no attribute 'name'\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:Issue encountered when serializing resources.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'_Resource' object has no attribute 'name'\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp1rk6_i60/model.ckpt.\n",
            "WARNING:tensorflow:Issue encountered when serializing resources.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'_Resource' object has no attribute 'name'\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 1.9459182, step = 0\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1...\n",
            "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp1rk6_i60/model.ckpt.\n",
            "WARNING:tensorflow:Issue encountered when serializing resources.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'_Resource' object has no attribute 'name'\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1...\n",
            "INFO:tensorflow:Loss for final step: 1.9459182.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-05-06T17:27:09Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp1rk6_i60/model.ckpt-1\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Inference Time : 10.69225s\n",
            "INFO:tensorflow:Finished evaluation at 2021-05-06-17:27:20\n",
            "INFO:tensorflow:Saving dict for global step 1: accuracy = 0.6341392, average_loss = 1.7333094, global_step = 1, loss = 1.7333094\n",
            "WARNING:tensorflow:Issue encountered when serializing resources.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'_Resource' object has no attribute 'name'\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1: /tmp/tmp1rk6_i60/model.ckpt-1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.6341392,\n",
              " 'average_loss': 1.7333094,\n",
              " 'global_step': 1,\n",
              " 'loss': 1.7333094}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intended-immune"
      },
      "source": [
        "# Splitting the dataset for the evaluation purpose\n",
        "Due to the size of the dataset and calculation time, I did not consider h-params tunning. The h-params here are the optimal values, based on the previous studies."
      ],
      "id": "intended-immune"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "musical-design"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=2)"
      ],
      "id": "musical-design",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suited-gardening"
      },
      "source": [
        "# Training the models\n",
        "The purpose of this training is to have a comparison between two gradient boosting models. The important thing in this comparison is that the [TFBT](https://www.tensorflow.org/tutorials/estimator/boosted_trees) model had made over the XGboost logic.\n",
        "\n",
        "Also, I modified the TFBT here based on the Sklearn Standard. You may check the [class](https://github.com/samanemami/TFBoostedTree/blob/main/TFBT.py) here.\n",
        "\n",
        "About the Boosting iteration, I set both to 10, so we can compare the performance of both methods at the early stage of learning."
      ],
      "id": "suited-gardening"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unlimited-fetish"
      },
      "source": [
        "xgb = xgboost.XGBClassifier(learning_rate=0.5,\n",
        "                            max_depth=2,\n",
        "                            n_estimators=10,\n",
        "                            subsample=0.75,\n",
        "                            min_child_weight=1)\n",
        "pipe_xgb = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", xgb)])\n",
        "x0 = time.time()\n",
        "pipe_xgb.fit(x_train, y_train)\n",
        "x1 = time.time()\n",
        "fit_ti_xgb = x1-x0\n",
        "err_xgb = pipe_xgb.score(x_test, y_test)"
      ],
      "id": "unlimited-fetish",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smart-trick"
      },
      "source": [
        "# XGboost results\n",
        "For the comparison, I considered the accuracy of the classification and the training time."
      ],
      "id": "smart-trick"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "southern-character",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "0541a8ff-0d82-43dc-938a-da04f83348f4"
      },
      "source": [
        "result = {}\n",
        "result['XGBoost accuracy'] = err_xgb\n",
        "result['XGBoost Training time'] = fit_ti_xgb\n",
        "pd.DataFrame(result, index=[\"Values\"])"
      ],
      "id": "southern-character",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>XGBoost accuracy</th>\n",
              "      <th>XGBoost Training time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Values</th>\n",
              "      <td>0.706346</td>\n",
              "      <td>33.967959</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        XGBoost accuracy  XGBoost Training time\n",
              "Values          0.706346              33.967959"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}